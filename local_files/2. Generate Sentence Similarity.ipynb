{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mecab part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "m = MeCab.Tagger (\"-Ochasen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykakasi import kakasi\n",
    "kakasi = kakasi()\n",
    "kakasi.setMode('H', 'a')\n",
    "kakasi.setMode('K', 'a')\n",
    "kakasi.setMode('J', 'a')\n",
    "conv = kakasi.getConverter()\n",
    "\n",
    "def mecab_list(text,ctr=0):\n",
    "    tagger = MeCab.Tagger(\"-Ochasen\")\n",
    "    tagger.parse('')\n",
    "    node = tagger.parseToNode(text)\n",
    "    word_class = []\n",
    "    result = []\n",
    "    while node:\n",
    "        word = node.surface\n",
    "        wclass = node.feature.split(',')\n",
    "        if (conv.do(word).isalpha() == True or conv.do(wclass[6]).isalpha() == True) and \\\n",
    "            (wclass[0] == '名詞' or (wclass[0] == '動詞' and wclass[1] == '自立') or wclass[0] == '形容詞' or wclass[0] == '`副詞'):\n",
    "            p1 = ''\n",
    "            p2 = ''\n",
    "            if wclass[0] == '名詞':\n",
    "                p1 = 'no'\n",
    "                p2 = 'g'\n",
    "            elif wclass[0] == '動詞':\n",
    "                p1 = 've'\n",
    "                if wclass[1] == '自立':\n",
    "                    p2 = 'i'\n",
    "            elif wclass[0] == '形容詞':\n",
    "                p1 = 'aj'\n",
    "                p2 = 'g'\n",
    "            else:\n",
    "                p1 = 'av'\n",
    "                p2 = 'g'\n",
    "                \n",
    "            try:\n",
    "                word_class.append((word,wclass[0],wclass[1],wclass[6],wclass[7],conv.do(wclass[6])))\n",
    "                result.append(conv.do(wclass[6]) + '_' + p1 + '_' + p2 + '_' + wclass[6])\n",
    "            except:\n",
    "                word_class.append((word,wclass[0],wclass[1],wclass[6],word,conv.do(word)))\n",
    "                result.append(conv.do(word) + '_' + p1 + '_' + p2 + '_' + wclass[6])\n",
    "        node = node.next\n",
    "    if ctr == 0:\n",
    "        return result\n",
    "    elif ctr == 1:\n",
    "        return word_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_tfidf_vector(path):\n",
    "    df = pd.read_csv(path,\n",
    "                    sep = \",\", \n",
    "                    encoding = \"utf-16\", \n",
    "                    error_bad_lines = 0,\n",
    "    )\n",
    "#     df = df.iloc[:9000,] ## Reducing data table since this is experimental coding.\n",
    "    print (\"There are \" + str(df.shape[0]) + \" candidates.\")\n",
    "\n",
    "    print(\"Preprocessing using MeCab...\")\n",
    "    time0 = time.time()\n",
    "    df[\"question_clean\"] = df[\"question\"].str.split('って英語でなんて言うの', expand=True)[0]\n",
    "    df['words'] = df['question_clean'].apply(mecab_list)\n",
    "    df['question_cd'] = df['words'].apply(' '.join)\n",
    "    df = df[df['words'].apply(len)!=0].reset_index(drop=True)\n",
    "    df['words_count'] = df['words'].apply(len)\n",
    "    time1 = time.time()\n",
    "    print(\"Preprocessing time: \",time1 - time0)    \n",
    "\n",
    "    corpus = [document.replace('*','_') for document in df['question_cd']]\n",
    "    vectorizer = TfidfVectorizer(lowercase=False)\n",
    "    \n",
    "    time0 = time.time()\n",
    "    corpus_vectorized = vectorizer.fit_transform(corpus)\n",
    "    time1 = time.time()\n",
    "    time1 - time0\n",
    "    print(\"TF_IDF processing time: \",time1 - time0)\n",
    "    \n",
    "    return df[['url','question_clean']], vectorizer, corpus_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 5339: expected 3 fields, saw 4\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9949 candidates.\n",
      "Preprocessing using MeCab...\n",
      "Preprocessing time:  30.7064425945282\n",
      "TF_IDF processing time:  0.11222171783447266\n",
      "Saved data frame with clean question lines to df_clean.pkl\n",
      "Saved trained vectorizer to vectorizer.pkl\n",
      "Saved vectorized corpus to corpus_vectorized.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean, vectorizer, corpus_vectorized  = attach_tfidf_vector(\"C:/Project/DMM_uKnow_Scraping/output.csv\")\n",
    "pickle.dump(df_clean, open('./df_clean.pkl', 'wb')), print(\"Saved data frame with clean question lines to df_clean.pkl\")\n",
    "pickle.dump(vectorizer, open('./vectorizer.pkl', 'wb')), print(\"Saved trained vectorizer to vectorizer.pkl\")\n",
    "pickle.dump(corpus_vectorized, open('./corpus_vectorized.pkl', 'wb')), print(\"Saved vectorized corpus to corpus_vectorized.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# import scipy.spatial.distance as spdis\n",
    "\n",
    "df_clean = pickle.load(open('./df_clean.pkl', 'rb'))\n",
    "vectorizer = pickle.load(open('./vectorizer.pkl', 'rb'))\n",
    "corpus_vectorized = pickle.load(open('./corpus_vectorized.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similarity(sample,disnum=5):\n",
    "    sample_mecabed = mecab_list(sample)\n",
    "    sample_vec = vectorizer.transform([' '.join(sample_mecabed).replace('*','_')]).toarray()\n",
    "\n",
    "    df_res = df_clean.copy()\n",
    "    df_res['similarity'] = np.dot(corpus_vectorized.toarray(), sample_vec.T) \n",
    "    # Cosine similarity = cosine values since the tf-idf vectors are l2 normed.\n",
    "\n",
    "    df_res.columns = ['DMM uknow URL','Question Line', 'Similarity']\n",
    "    \n",
    "    return df_res[df_res['Similarity']>0].sort_values(by='Similarity', ascending=False).head(disnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = '急に必要になる時だってあります'\n",
    "sample = '天気予報を見てから出かける'\n",
    "# sample = '無料枠があるので、今回はそれを使っていきたいと思います'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time:  0.16954636573791504\n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "top5res = generate_similarity(sample,5)\n",
    "time1 = time.time()\n",
    "print(\"processing time: \", time1-time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DMM uknow URL</th>\n",
       "      <th>Question Line</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>https://eikaiwa.dmm.com/uknow/questions/53369/</td>\n",
       "      <td>天気予報の精度がとても高い</td>\n",
       "      <td>0.578216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>https://eikaiwa.dmm.com/uknow/questions/46524/</td>\n",
       "      <td>出かける</td>\n",
       "      <td>0.509022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>https://eikaiwa.dmm.com/uknow/questions/33921/</td>\n",
       "      <td>天気</td>\n",
       "      <td>0.509022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>https://eikaiwa.dmm.com/uknow/questions/54222/</td>\n",
       "      <td>〇〇の天気はどうですか？</td>\n",
       "      <td>0.509022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>https://eikaiwa.dmm.com/uknow/questions/28819/</td>\n",
       "      <td>出かけなければいけなくなりました</td>\n",
       "      <td>0.450107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       DMM uknow URL     Question Line  \\\n",
       "4146  https://eikaiwa.dmm.com/uknow/questions/53369/     天気予報の精度がとても高い   \n",
       "1241  https://eikaiwa.dmm.com/uknow/questions/46524/              出かける   \n",
       "2844  https://eikaiwa.dmm.com/uknow/questions/33921/                天気   \n",
       "2780  https://eikaiwa.dmm.com/uknow/questions/54222/     〇〇の天気はどうですか？　   \n",
       "7638  https://eikaiwa.dmm.com/uknow/questions/28819/  出かけなければいけなくなりました   \n",
       "\n",
       "      Similarity  \n",
       "4146    0.578216  \n",
       "1241    0.509022  \n",
       "2844    0.509022  \n",
       "2780    0.509022  \n",
       "7638    0.450107  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
